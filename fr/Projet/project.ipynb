{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "## Dépendance\n",
    "Les dépendances suivantes sont nécessaires pour l'execution du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install SPARQLWrapper\n",
    "! pip install exifread\n",
    "! pip install pandas\n",
    "! pip install PIL\n",
    "! pip install ipywidgets\n",
    "! pip install -U scikit-learn\n",
    "! pip install graphviz\n",
    "! pip install pydotplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecte de données\n",
    "Collecte des images via wikidata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# Get cities\n",
    "query = \"\"\"SELECT DISTINCT ?grandeville ?grandevilleLabel ?pays ?paysLabel ?image {\n",
    "  ?grandeville wdt:P31 wd:Q1549591;\n",
    "               wdt:P17 ?pays;\n",
    "               wdt:P18 ?image.\n",
    " SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr\". }\n",
    "}\n",
    "LIMIT 15\"\"\"\n",
    "\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (\n",
    "        sys.version_info[0],\n",
    "        sys.version_info[1],\n",
    "    )\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "\n",
    "array = []\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    array.append(\n",
    "        (\n",
    "            result[\"grandevilleLabel\"][\"value\"],\n",
    "            result[\"paysLabel\"][\"value\"],\n",
    "            result[\"image\"][\"value\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "dataframe = pd.DataFrame(array, columns=[\"ville\", \"pays\", \"image\"])\n",
    "dataframe = dataframe.astype(\n",
    "    dtype={\"ville\": \"<U200\", \"pays\": \"<U200\", \"image\": \"<U200\"}\n",
    ")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Téléchargement des images\n",
    "Téléchargements des images récupérés précedemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def download_image(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    request = requests.get(url, allow_redirects=True, headers=headers, stream=True)\n",
    "    if request.status_code == 200:\n",
    "        # Create 'images' directory if it doesn't exist\n",
    "        if not os.path.exists(\"images\"):\n",
    "            os.makedirs(\"images\")\n",
    "\n",
    "        # Extract the filename from the URL and save the image in 'images' directory\n",
    "        filename = os.path.join(\"images\", os.path.basename(url))\n",
    "        with open(filename, \"wb\") as image:\n",
    "            request.raw.decode_content = True\n",
    "            shutil.copyfileobj(request.raw, image)\n",
    "    return request.status_code\n",
    "\n",
    "def clear_images_directory():\n",
    "    # Clear 'images' directory if it exists\n",
    "    if os.path.exists(\"images\"):\n",
    "        shutil.rmtree(\"images\")\n",
    "\n",
    "# Clear 'images' directory before every execution\n",
    "clear_images_directory()\n",
    "\n",
    "# Assuming 'dataframe' is a DataFrame containing URLs under column 'image'\n",
    "# Apply the download_image function to each URL in the 'image' column\n",
    "dataframe.image.apply(download_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enregistrement des métadonnées\n",
    "#### Import\n",
    "Ensemble des imports nécessaires aux executions du code suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image, TiffImagePlugin\n",
    "import PIL.ExifTags\n",
    "import pandas as pd\n",
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définiton du chemin du répertoire et initialisation de la liste pour stocker les métadonnées :\n",
    "Définition du chemin dans lequel sont stocké les images et renvoi d'erreur si celui-ci n'existe pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"images\"\n",
    "all_metadata = []\n",
    "\n",
    "if not os.path.isdir(directory_path):\n",
    "    print(f\"Error: Directory '{directory_path}' does not exist!\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des fonctions pour convertir les types de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast(v):\n",
    "    if isinstance(v, TiffImagePlugin.IFDRational):\n",
    "        if v.denominator == 0:\n",
    "            return None  # Handle division by zero gracefully\n",
    "        return float(v.numerator) / float(v.denominator)\n",
    "    elif isinstance(v, tuple):\n",
    "        return tuple(cast(t) for t in v)\n",
    "    elif isinstance(v, bytes):\n",
    "        return v.decode(errors=\"replace\")\n",
    "    elif isinstance(v, dict):\n",
    "        for kk, vv in v.items():\n",
    "            v[kk] = cast(vv)\n",
    "        return v\n",
    "    else:\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition de la fonction pour obtenir les couleurs principales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_main_colors(image_path, num_clusters):\n",
    "    # Open and resize the image\n",
    "    imgfile = image_path\n",
    "    imgfile.thumbnail((100, 100))  # Resize the image to a smaller size\n",
    "    numarray = np.array(imgfile)  # Convert image to numpy array\n",
    "\n",
    "    # Flatten the image array\n",
    "    numarray = numarray.reshape((-1, 3))\n",
    "\n",
    "    # Sample a subset of pixels (optional)\n",
    "    np.random.shuffle(numarray)\n",
    "    num_samples = min(10000, len(numarray))  # Adjust the number of samples if needed\n",
    "    numarray = numarray[:num_samples]\n",
    "\n",
    "    # Perform KMeans clustering\n",
    "    clusters = KMeans(n_clusters=num_clusters, n_init=2)\n",
    "    clusters.fit(numarray)\n",
    "\n",
    "    # Get the main colors\n",
    "    main_colors = clusters.cluster_centers_.astype(int)\n",
    "\n",
    "    return main_colors.tolist()  # Convert array to list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des couleurs proches des couleurs principales pour l'ensemble des images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to find the closest main color for a given RGB value\n",
    "def find_closest_color(rgb):\n",
    "    main_colors = [\n",
    "        [0, 0, 0],      # Black\n",
    "        [255, 255, 255],  # White\n",
    "        [255, 0, 0],    # Red\n",
    "        [0, 255, 0],    # Green\n",
    "        [0, 0, 255],    # Blue\n",
    "        [255, 255, 0],  # Yellow\n",
    "        [255, 0, 255],  # Magenta\n",
    "        [0, 255, 255],  # Cyan\n",
    "        [128, 128, 128], # Grey\n",
    "        [255, 165, 0],   # Orange\n",
    "        [0, 128, 0],     # Dark Green\n",
    "        [128, 0, 128],   # Purple\n",
    "        [128, 0, 0],     # Maroon\n",
    "        [0, 128, 128],   # Teal\n",
    "        [128, 128, 0],   # Olive\n",
    "        [0, 255, 255],   # Light Blue\n",
    "        [210, 105, 30],  # Chocolate\n",
    "        [139, 69, 19],   # Saddle Brown\n",
    "        [255, 192, 203], # Pink\n",
    "        [0, 0, 128],     # Navy\n",
    "        [220, 20, 60]    # Crimson\n",
    "        # Add more main colors as needed\n",
    "    ]\n",
    "\n",
    "    # Convert list of main colors to numpy array for vectorized calculations\n",
    "    main_colors = np.array(main_colors)\n",
    "\n",
    "    # Convert input RGB list to numpy array\n",
    "    rgb = np.array(rgb)\n",
    "\n",
    "    # Calculate Euclidean distances between input RGB and all main colors\n",
    "    distances = np.linalg.norm(main_colors - rgb, axis=1)\n",
    "\n",
    "    # Find index of the closest main color\n",
    "    closest_index = np.argmin(distances)\n",
    "\n",
    "    return main_colors[closest_index].tolist()  # Convert NumPy array to list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition de classe de taille pour catégoriser les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image_size(image_size):\n",
    "    \"\"\"\n",
    "    Classify the image into different size classes based on its dimensions.\n",
    "\n",
    "    Parameters:\n",
    "        image_size (tuple): The dimensions of the image in the format (width, height).\n",
    "\n",
    "    Returns:\n",
    "        str: The class label for the image size.\n",
    "    \"\"\"\n",
    "    width, height = image_size\n",
    "\n",
    "    # Define size thresholds for different classes\n",
    "    small_threshold = 500  # threshold for small images\n",
    "    medium_threshold = 1000  # threshold for medium images\n",
    "\n",
    "    # Classify the image based on its dimensions\n",
    "    if width <= small_threshold or height <= small_threshold:\n",
    "        return \"Small\"\n",
    "    elif width <= medium_threshold or height <= medium_threshold:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Large\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition de la fonction pour obtenir les propriétés des images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_metadata(imgfile, hasExif):\n",
    "    \"\"\"\n",
    "    Get metadata of an image file including format, size, main colors, closest colors, and orientation.\n",
    "\n",
    "    Parameters:\n",
    "        imgfile (PIL.Image.Image): The image file object.\n",
    "        hasExif (bool): Indicates whether the image has Exif metadata.\n",
    "\n",
    "    Returns:\n",
    "        dict: Metadata of the image.\n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "\n",
    "    # Get image format\n",
    "    metadata['format'] = imgfile.format\n",
    "\n",
    "    # Get image size\n",
    "    metadata['size'] = imgfile.size\n",
    "\n",
    "    # Classify image size\n",
    "    image_size = imgfile.size\n",
    "    metadata['size_class'] = classify_image_size(image_size)\n",
    "\n",
    "    # Get 3 main colors\n",
    "    main_colors = get_main_colors(imgfile, 3)\n",
    "    metadata[\"main_colors\"] = main_colors\n",
    "\n",
    "    # Get closest colors based on the 3 main colors\n",
    "    closest_colors = [find_closest_color(color) for color in main_colors]\n",
    "    metadata[\"closest_colors\"] = closest_colors\n",
    "\n",
    "    # Get image orientation\n",
    "    if hasExif:\n",
    "        exif = dict(imgfile._getexif().items())\n",
    "        if exif:\n",
    "            orientation = exif.get(274)\n",
    "            if orientation == 1:\n",
    "                metadata['orientation'] = 'Landscape'\n",
    "            elif orientation == 3:\n",
    "                metadata['orientation'] = 'Portrait'\n",
    "            else:\n",
    "                metadata['orientation'] = 'Unknown'\n",
    "        else:\n",
    "            metadata['orientation'] = 'Unknown'\n",
    "    else:\n",
    "        metadata['orientation'] = 'Unknown'\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parcours des fichiers du répertoire et extraction des métadonnées\n",
    "\n",
    "Ajout comme balises le format, la taille et les 3 couleurs principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from PIL import Image, TiffImagePlugin\n",
    "import PIL.ExifTags\n",
    "\n",
    "directory_path = \"images\"\n",
    "all_metadata = []\n",
    "\n",
    "if not os.path.isdir(directory_path):\n",
    "    print(f\"Error: Directory '{directory_path}' does not exist!\")\n",
    "    sys.exit()\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if os.path.isfile(os.path.join(directory_path, filename)) and filename.lower().endswith((\".jpg\", \".png\")):\n",
    "        print(f\"Found image: {filename}\")\n",
    "\n",
    "        try:\n",
    "            imgfile = Image.open(os.path.join(directory_path, filename))\n",
    "            exif_data = imgfile._getexif()\n",
    "            \n",
    "            metadata_dict = {}\n",
    "            \n",
    "            hasExif = False\n",
    "\n",
    "            if exif_data:\n",
    "                hasExif = True\n",
    "                for k, v in imgfile._getexif().items():\n",
    "                    if k in PIL.ExifTags.TAGS:\n",
    "                        v = cast(v)\n",
    "                        metadata_dict[PIL.ExifTags.TAGS[k]] = v\n",
    "            else:\n",
    "                print(f\"  - No EXIF data found for {filename}\")\n",
    "\n",
    "            # Get additional image metadata (format, size, orientation)\n",
    "            image_metadata = get_image_metadata(imgfile, hasExif)\n",
    "            metadata_dict.update(image_metadata)\n",
    "            \n",
    "            all_metadata.append({filename: metadata_dict})\n",
    "            if not metadata_dict:\n",
    "                print(f\"  - No metadata found for {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error processing {filename}: {e}\")\n",
    "\n",
    "directory_path = \"output\"\n",
    "output_file = \"directory_metadata.json\"\n",
    "\n",
    "if not os.path.exists(directory_path):\n",
    "            os.makedirs(directory_path)\n",
    "\n",
    "output_location = directory_path + \"/\" + output_file\n",
    "with open(output_location, \"w\") as json_file:\n",
    "    json.dump(all_metadata, json_file, indent=4)\n",
    "\n",
    "print(f\"Directory metadata saved to {output_location} (if no errors occurred)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étiquetage et annotation\n",
    "### Utilisation des utilisateur pour tagger les images\n",
    "Possibilité pour les utilisateurs d'ajouter des tags aux images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import GridspecLayout\n",
    "\n",
    "images = []\n",
    "\n",
    "# Loop through files in the \"./images\" directory\n",
    "for file in listdir(\"./images\"):\n",
    "    # Check if the file is a PNG or JPG image\n",
    "    if file.endswith((\".png\", \".jpg\")):\n",
    "        images.append(\"./images/\" + file)\n",
    "        \n",
    "values = []\n",
    "\n",
    "# Create text boxes\n",
    "text_boxes = [widgets.Text(value='', description='Tag:') for _ in range(len(images))]\n",
    "\n",
    "# Create the GridspecLayout widget\n",
    "layout = GridspecLayout(n_columns=2, n_rows=len(images), width='400px')\n",
    "for i, (img, text_box) in enumerate(zip(images, text_boxes)):\n",
    "    with open(img, \"rb\") as file:\n",
    "        image = file.read()\n",
    "    image_widget = widgets.Image(\n",
    "        value=image,\n",
    "        format='png',\n",
    "        width=100,\n",
    "        height=100,\n",
    "    )\n",
    "    layout[i,0] = image_widget\n",
    "    layout[i, 1] = text_box\n",
    "\n",
    "# Button to get selected images\n",
    "button = widgets.Button(description=\"Select\")\n",
    "\n",
    "# Output widget to display selected values\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to get selected values\n",
    "def get_selected_values(btn):\n",
    "    global values\n",
    "    values = []\n",
    "    selected_values = [(file.split(\"/\")[-1], text_box.value) for file, text_box in zip(images, text_boxes) if text_box.value]\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(\"Selected Values:\")\n",
    "        for file_name, value in selected_values:\n",
    "            print(f\"{file_name}: {value}\")\n",
    "            values.append((file_name, value))\n",
    "    print(values)\n",
    "        \n",
    "\n",
    "# Link button click event to function\n",
    "button.on_click(get_selected_values)\n",
    "\n",
    "# Display the layout and button\n",
    "display(layout, button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde des modifications de métadonnées:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the existing JSON file\n",
    "with open('output/directory_metadata.json', 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Iterate through the values and update the JSON data\n",
    "for file_name, value in values:\n",
    "    # Search for the corresponding object in the JSON data\n",
    "    for obj in json_data:\n",
    "        for filename, details in obj.items():\n",
    "            # Check if the file name matches\n",
    "            if filename == file_name:\n",
    "                # Update the value\n",
    "                details['tag'] = value\n",
    "                break  # Exit inner loop if match found\n",
    "        else:\n",
    "            continue  # Continue to next iteration if no match found\n",
    "        break  # Exit outer loop if match found\n",
    "\n",
    "# Save the updated JSON data back to the file\n",
    "with open('output/directory_metadata.json', 'w') as file:\n",
    "    json.dump(json_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses de données\n",
    "Ajout de tags favori pour le user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import GridspecLayout\n",
    "\n",
    "# Get the list of images in the \"./images\" directory\n",
    "images = []\n",
    "for file in listdir(\"./images\"):\n",
    "    if file.endswith((\".png\", \".jpg\")):\n",
    "        images.append(file)\n",
    "\n",
    "# Create checkboxes for each image\n",
    "checkboxes = [widgets.Checkbox(value=False, description='Favorite') for _ in range(len(images))]\n",
    "\n",
    "# Create the GridspecLayout widget\n",
    "layout = GridspecLayout(n_columns=2, n_rows=len(images), width='400px')\n",
    "for i, (image_name, checkbox) in enumerate(zip(images, checkboxes)):\n",
    "    with open(f\"./images/{image_name}\", \"rb\") as file:\n",
    "        image_data = file.read()\n",
    "    image_widget = widgets.Image(\n",
    "        value=image_data,\n",
    "        format='png',\n",
    "        width=100,\n",
    "        height=100,\n",
    "    )\n",
    "    layout[i, 0] = image_widget\n",
    "    layout[i, 1] = checkbox\n",
    "\n",
    "# Button to get selected images\n",
    "button = widgets.Button(description=\"Select\")\n",
    "\n",
    "# Output widget to display selected images\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to get selected images\n",
    "def get_selected_images(btn):\n",
    "    global selected_image_names\n",
    "    selected_image_names = [images[i] for i, checkbox in enumerate(checkboxes) if checkbox.value]\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(\"Selected Image Names:\")\n",
    "        for image_name in selected_image_names:\n",
    "            print(image_name)\n",
    "    print(selected_image_names)\n",
    "\n",
    "# Link button click event to function\n",
    "button.on_click(get_selected_images)\n",
    "\n",
    "# Display the layout and button\n",
    "display(layout, button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde des propriétés utilisateurs de l'image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction d'extraction des propritées des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_properties(image_filenames, json_data):\n",
    "    properties = []\n",
    "    for filename in image_filenames:\n",
    "        for obj in json_data:\n",
    "            for key, details in obj.items():\n",
    "                if key == filename:\n",
    "                    image_properties = {\n",
    "                        'filename': filename,\n",
    "                        'make': details.get('Make', ''),\n",
    "                        'model': details.get('Model', ''),\n",
    "                        'format': details.get('format', ''),\n",
    "                        'size_class': details.get('size_class', ''),\n",
    "                        'closest_colors': details.get('closest_colors', []),\n",
    "                        'orientation': details.get('orientation', ''),\n",
    "                        'tag': details.get('tag', '')\n",
    "                    }\n",
    "                    properties.append(image_properties)\n",
    "    return properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction de sauvegarde de données d'utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_user_properties(username, selected_image_names, json_data):\n",
    "    # Extract properties\n",
    "    extracted_properties = extract_properties(selected_image_names, json_data)\n",
    "\n",
    "    # JSON object to store user and properties\n",
    "    user_properties = {\n",
    "        'username': username,\n",
    "        'properties': extracted_properties\n",
    "    }\n",
    "\n",
    "    # Load existing user properties or initialize an empty list\n",
    "    if os.path.isfile('user_properties.json') and os.path.getsize('user_properties.json') > 0:\n",
    "        with open('user_properties.json', 'r') as file:\n",
    "            all_users_properties = json.load(file)\n",
    "    else:\n",
    "        all_users_properties = []\n",
    "\n",
    "    # Add or update user properties\n",
    "    user_exists = False\n",
    "    for user_data in all_users_properties:\n",
    "        if user_data['username'] == username:\n",
    "            user_data['properties'] = extracted_properties\n",
    "            user_exists = True\n",
    "            break\n",
    "\n",
    "    if not user_exists:\n",
    "        all_users_properties.append(user_properties)\n",
    "\n",
    "    # Write all user properties to the JSON file\n",
    "    with open('user_properties.json', 'w') as file:\n",
    "        json.dump(all_users_properties, file, indent=4)\n",
    "\n",
    "    print(f\"User properties for {username} have been saved to 'user_properties.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création manuelle de 2 utilisateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Load JSON data from file\n",
    "with open('output/directory_metadata.json', 'r') as file:\n",
    "    try:\n",
    "        json_data = json.load(file)\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        json_data = []\n",
    "\n",
    "# Sample image filenames for user1 (replace with your list of selected image names)\n",
    "user1_image_names = ['Ch%C3%A2teau%20Frontenac%2C%20Quebec%20city%2C%20Canada.jpg', \n",
    "                     'Havenwelten%20%C3%9Cberblick%20Bremerhaven%202013.jpg', \n",
    "                     'Copenhagen%20-%20view%20from%20Christiansborg%20castle.jpg']\n",
    "\n",
    "# Save properties for user1\n",
    "save_user_properties('user41', user1_image_names, json_data)\n",
    "\n",
    "# Sample image filenames for user2 (replace with your list of selected image names)\n",
    "user2_image_names = ['Petrozavodsk%20Collage%202020.png', \n",
    "                     'Bras%C3%ADlia%20Collage.png', \n",
    "                     'Pskov%20asv07-2018%20Kremlin%20before%20sunset.jpg']\n",
    "\n",
    "# Save properties for user2\n",
    "save_user_properties('user42', user2_image_names, json_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création automatique de plusieurs utilisateur avec un nombre maximum d'image favorites donné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "def generate_users_and_properties(num_users, image_folder, max_images_per_user):\n",
    "    # List files in the image folder\n",
    "    image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "\n",
    "    for i in range(num_users):\n",
    "        # Generate a random username\n",
    "        username = ''.join(random.choices(string.ascii_letters + string.digits, k=8))\n",
    "\n",
    "        # Select a random number of images for this user\n",
    "        num_images = random.randint(1, max_images_per_user)\n",
    "        selected_images = random.sample(image_files, num_images)\n",
    "\n",
    "        # Call save_user_properties function\n",
    "        save_user_properties(username, selected_images, json_data)\n",
    "\n",
    "generate_users_and_properties(5, 'images', 10)  # Generates 5 users, each with up to 3 random images from the 'images' folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Représentation des couleurs les plus présentes sous forme graphique pour l'ensemble de la liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Open the JSON file\n",
    "with open('output/directory_metadata.json', 'r') as file:\n",
    "    # Load the JSON data\n",
    "    json_data = json.load(file)\n",
    "\n",
    "    # Create a list to store all the closest colors\n",
    "    all_closest_colors = []\n",
    "\n",
    "    # Iterate through each object in the list\n",
    "    for obj in json_data:\n",
    "        # Get the dictionary within each object\n",
    "        for filename, details in obj.items():\n",
    "            # Access the \"closest_colors\" key within each dictionary\n",
    "            closest_colors = details.get(\"closest_colors\")\n",
    "            if closest_colors:\n",
    "                # Extend the list of all closest colors with the closest colors of the current image\n",
    "                all_closest_colors.extend(closest_colors)\n",
    "\n",
    "# Count the occurrences of each closest color\n",
    "unique_closest_colors, counts = np.unique(all_closest_colors, axis=0, return_counts=True)\n",
    "\n",
    "# Calculate percentages\n",
    "total_count = sum(counts)\n",
    "percentages = [(count / total_count) * 100 for count in counts]\n",
    "\n",
    "# Create labels with RGB values and percentages\n",
    "labels = [f\"RGB: {color}, {percentage:.2f}%\" for color, percentage in zip(unique_closest_colors, percentages)]\n",
    "sizes = counts\n",
    "colors = [f\"#{r:02x}{g:02x}{b:02x}\" for r, g, b in unique_closest_colors]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sizes, labels=labels, colors=colors, startangle=90)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.title('Pie Chart of Closest Colors')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Représentation des couleurs les plus présentes sous forme graphique pour chaque image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Open the JSON file\n",
    "with open('output/directory_metadata.json', 'r') as file:\n",
    "    # Load the JSON data\n",
    "    json_data = json.load(file)\n",
    "\n",
    "    # Iterate through each object in the list\n",
    "    for obj in json_data:\n",
    "        # Create a list to store all the closest colors for this image\n",
    "        all_main_colors = []\n",
    "\n",
    "        # Get the dictionary within each object\n",
    "        for _, details in obj.items():\n",
    "            # Access the \"closest_colors\" key within each dictionary\n",
    "            main_colors = details.get(\"main_colors\")\n",
    "            if main_colors:\n",
    "                # Extend the list of all closest colors with the closest colors of the current image\n",
    "                all_main_colors.extend(main_colors)\n",
    "\n",
    "        # Count the occurrences of each closest color for this image\n",
    "        unique_main_colors, counts = np.unique(all_main_colors, axis=0, return_counts=True)\n",
    "\n",
    "        # Calculate percentages\n",
    "        total_count = sum(counts)\n",
    "        percentages = [(count / total_count) * 100 for count in counts]\n",
    "\n",
    "        # Create labels with RGB values and percentages\n",
    "        labels = [f\"RGB: {color}, {percentage:.2f}%\" for color, percentage in zip(unique_main_colors, percentages)]\n",
    "        sizes = counts\n",
    "        colors = [f\"#{r:02x}{g:02x}{b:02x}\" for r, g, b in unique_main_colors]\n",
    "\n",
    "        # Plot the pie chart for this image\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.pie(sizes, labels=labels, colors=colors, startangle=90)\n",
    "        plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "        plt.title('Pie Chart of Main Colors for Image')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Représentation des années de prise des images et de la répartition des classes de tailles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Open the JSON file\n",
    "with open('output/directory_metadata.json', 'r') as file:\n",
    "    # Load the JSON data\n",
    "    json_data = json.load(file)\n",
    "\n",
    "    # Create a list to store all the dates\n",
    "    all_dates = []\n",
    "    \n",
    "    # Create a dictionary to store the counts of each size_class\n",
    "    all_size_class = []\n",
    "    \n",
    "    all_make = []\n",
    "    all_model = []\n",
    "\n",
    "    # Iterate through each object in the list\n",
    "    for obj in json_data:\n",
    "        # Get the dictionary within each object\n",
    "        for filename, details in obj.items():\n",
    "            # Access the \"DateTimeOriginal\" key within each dictionary\n",
    "            datetime_str = details.get(\"DateTimeOriginal\")\n",
    "            if datetime_str:\n",
    "                # Split the datetime string and keep only the date part\n",
    "                year = datetime_str.split(':')[0]\n",
    "                # Append the date to the list of all dates\n",
    "                all_dates.append(year)\n",
    "            size_class = details.get(\"size_class\")\n",
    "            if size_class:\n",
    "                all_size_class.append(size_class)\n",
    "            make = details.get(\"Make\")\n",
    "            if make:\n",
    "                all_make.append(make)\n",
    "            model = details.get(\"Model\")\n",
    "            if model:\n",
    "                all_model.append(model)\n",
    "\n",
    "# Count the occurrences of each date\n",
    "unique_dates, counts = np.unique(all_dates, return_counts=True)\n",
    "\n",
    "# Extracting unique size classes and their counts\n",
    "unique_size_classes, counts_size_classes = np.unique(all_size_class, return_counts=True)\n",
    "\n",
    "unique_make, counts_make = np.unique(all_make, return_counts=True)\n",
    "unique_model, counts_model = np.unique(all_model, return_counts=True)\n",
    "\n",
    "\n",
    "# Creating a subplot grid with 2 rows and 2 columns\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plotting the first diagram\n",
    "axs[0, 0].bar(unique_dates, counts, color='skyblue')\n",
    "axs[0, 0].set_xlabel('Date')\n",
    "axs[0, 0].set_ylabel('Frequency')\n",
    "axs[0, 0].set_title('Bar Diagram of Dates (DateTimeOriginal)')\n",
    "axs[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plotting the second diagram\n",
    "axs[0, 1].bar(unique_size_classes, counts_size_classes, color='skyblue')\n",
    "axs[0, 1].set_xlabel('Size Class')\n",
    "axs[0, 1].set_ylabel('Frequency')\n",
    "axs[0, 1].set_title('Bar Diagram of Size Classes')\n",
    "axs[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plotting the third diagram\n",
    "axs[1, 0].bar(unique_make, counts_make, color='skyblue')\n",
    "axs[1, 0].set_xlabel('Make')\n",
    "axs[1, 0].set_ylabel('Frequency')\n",
    "axs[1, 0].set_title('Bar Diagram of Make')\n",
    "axs[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plotting the fourth diagram\n",
    "axs[1, 1].bar(unique_model, counts_model, color='skyblue')\n",
    "axs[1, 1].set_xlabel('Model')\n",
    "axs[1, 1].set_ylabel('Frequency')\n",
    "axs[1, 1].set_title('Bar Diagram of Model')\n",
    "axs[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des couleurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogramme de couleurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Open the JSON file\n",
    "with open('output/directory_metadata.json', 'r') as file:\n",
    "    # Load the JSON data\n",
    "    json_data = json.load(file)\n",
    "\n",
    "    # Calculate the number of images\n",
    "    num_images = len(json_data)\n",
    "\n",
    "    # Calculate the number of rows and columns for subplots\n",
    "    num_rows = num_images\n",
    "    num_cols = 1\n",
    "\n",
    "    # Create a new figure\n",
    "    plt.figure(figsize=(10, 6*num_rows))\n",
    "\n",
    "    # Iterate through each object in the list\n",
    "    for idx, obj in enumerate(json_data, 1):\n",
    "        # Get the filename and the dictionary within each object\n",
    "        for filename, details in obj.items():\n",
    "            # Open the image file\n",
    "            imgfile = Image.open(f\"images/{filename}\")\n",
    "            histogram = imgfile.histogram()\n",
    "            red = histogram[0:255]\n",
    "            green = histogram[256:511]\n",
    "            blue = histogram[512:767]\n",
    "            x = range(255)\n",
    "            y = []\n",
    "            for i in x:\n",
    "                y.append((red[i], green[i], blue[i]))\n",
    "\n",
    "            # Add subplot for each image\n",
    "            plt.subplot(num_rows, num_cols, idx)\n",
    "            plt.plot(x, y)\n",
    "            plt.title(f'Histogram of RGB Channels for {filename}')\n",
    "            plt.xlabel('Intensity')\n",
    "            plt.ylabel('Frequency')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the combined output\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Système de recommandation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des images favorites pour un utilisateur donné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def extract_image_properties_with_favorite(directory_metadata, user_properties):\n",
    "    image_properties_list = []\n",
    "\n",
    "    for entry in directory_metadata:\n",
    "        filename, details = list(entry.items())[0]\n",
    "        image_properties = {\n",
    "            'filename': filename,\n",
    "            'make': details.get('Make', ''),\n",
    "            'model': details.get('Model', ''),\n",
    "            'format': details.get('format', ''),\n",
    "            'size_class': details.get('size_class', ''),\n",
    "            'closest_colors': details.get('closest_colors', []),\n",
    "            'orientation': details.get('orientation', ''),\n",
    "            'tag': details.get('tag', '')\n",
    "        }\n",
    "\n",
    "        # Check if the image filename is present in user's properties\n",
    "        for user in user_properties:\n",
    "            if user[\"username\"] == 'Mpxv3raF':\n",
    "                for prop in user['properties']:\n",
    "                    if prop['filename'] == filename:\n",
    "                        image_properties['favorite'] = 'Favorite'\n",
    "                        break\n",
    "                else:\n",
    "                    continue\n",
    "                break\n",
    "        else:\n",
    "            image_properties['favorite'] = 'NotFavorite'\n",
    "\n",
    "        image_properties_list.append(image_properties)\n",
    "\n",
    "    return image_properties_list\n",
    "\n",
    "# Load directory metadata from JSON file\n",
    "with open('output/directory_metadata.json', 'r') as file:\n",
    "    directory_metadata = json.load(file)\n",
    "\n",
    "# Load user properties from JSON file\n",
    "with open('user_properties.json', 'r') as file:\n",
    "    user_properties = json.load(file)\n",
    "\n",
    "# Extract image properties with favorite status\n",
    "image_properties_with_favorite = extract_image_properties_with_favorite(directory_metadata, user_properties)\n",
    "\n",
    "# Keep only 'filename' and 'favorite' properties for each dictionary\n",
    "filtered_data = [{'filename': item['filename'], 'favorite': item['favorite']} for item in image_properties_with_favorite]\n",
    "\n",
    "print(filtered_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation d'images similaire succeptible de plaire à l'utilisateur choisi plus haut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def transform_data(input_data):\n",
    "    data = []\n",
    "    result = []\n",
    "\n",
    "    for item in input_data:\n",
    "        make = item['make']\n",
    "        model = item['model']\n",
    "        format = item['format']\n",
    "        size_class = item['size_class']\n",
    "        closest_colors = item['closest_colors']  # Assuming list of colors\n",
    "        orientation = item['orientation']\n",
    "        tag = item['tag']\n",
    "        favorite = item['favorite']\n",
    "\n",
    "        # Assuming you have 3 color values in the list\n",
    "        color1, color2, color3 = closest_colors\n",
    "\n",
    "        # No string conversion needed, use color values directly\n",
    "        data.append([make, model, format, size_class, color1, color2, color3, orientation, tag])\n",
    "        result.append(favorite)\n",
    "\n",
    "    return data, result\n",
    "\n",
    "# Example usage:\n",
    "input_data = image_properties_with_favorite\n",
    "\n",
    "data, result = transform_data(input_data)\n",
    "\n",
    "prediction_array = []\n",
    "\n",
    "# Create DataFrame\n",
    "column_names = [\"make\", \"model\", \"format\", \"size_class\", \"color1\", \"color2\", \"color3\", \"orientation\", \"tag\"]\n",
    "dataframe = pd.DataFrame(data, columns=column_names)\n",
    "\n",
    "# Convert color lists to strings\n",
    "dataframe[\"color1\"] = dataframe[\"color1\"].astype(str)\n",
    "dataframe[\"color2\"] = dataframe[\"color2\"].astype(str)\n",
    "dataframe[\"color3\"] = dataframe[\"color3\"].astype(str)\n",
    "\n",
    "# Initialize LabelEncoders\n",
    "le_make = LabelEncoder()\n",
    "le_model = LabelEncoder()\n",
    "le_format = LabelEncoder()\n",
    "le_size_class = LabelEncoder()\n",
    "le_color1 = LabelEncoder()\n",
    "le_color2 = LabelEncoder()\n",
    "le_color3 = LabelEncoder()\n",
    "le_orientation = LabelEncoder()\n",
    "le_tag = LabelEncoder()\n",
    "le_favorite = LabelEncoder()\n",
    "\n",
    "# Fit and transform categorical features\n",
    "dataframe[\"make\"] = le_make.fit_transform(dataframe[\"make\"])\n",
    "dataframe[\"model\"] = le_model.fit_transform(dataframe[\"model\"])\n",
    "dataframe[\"format\"] = le_format.fit_transform(dataframe[\"format\"])\n",
    "dataframe[\"size_class\"] = le_size_class.fit_transform(dataframe[\"size_class\"])\n",
    "dataframe[\"color1\"] = le_color1.fit_transform(dataframe[\"color1\"])\n",
    "dataframe[\"color2\"] = le_color2.fit_transform(dataframe[\"color2\"])\n",
    "dataframe[\"color3\"] = le_color3.fit_transform(dataframe[\"color3\"])\n",
    "dataframe[\"orientation\"] = le_orientation.fit_transform(dataframe[\"orientation\"])\n",
    "dataframe[\"tag\"] = le_tag.fit_transform(dataframe[\"tag\"])\n",
    "\n",
    "# Create DataFrame for favorite column\n",
    "resultframe = pd.DataFrame(result, columns=[\"favorite\"])\n",
    "\n",
    "# Convert 'favorite' to numerical labels\n",
    "resultframe[\"favorite\"] = le_favorite.fit_transform(resultframe[\"favorite\"])\n",
    "\n",
    "# Use of random forest classifier\n",
    "rfc = RandomForestClassifier(n_estimators=10, max_depth=2, random_state=0)\n",
    "rfc = rfc.fit(dataframe.values, resultframe.values.ravel())\n",
    "\n",
    "for item in input_data:\n",
    "    predicted_make = item['make']\n",
    "    predicted_model = item['model']\n",
    "    predicted_format = item['format']\n",
    "    predicted_size_class = item['size_class']\n",
    "    closest_colors = item['closest_colors']  # Assuming list of colors\n",
    "    predicted_orientation = item['orientation']\n",
    "    predicted_tag = item['tag']\n",
    "\n",
    "    # Assuming you have 3 color values in the list\n",
    "    color1, color2, color3 = closest_colors\n",
    "    # Prediction with handling unseen colors (optional)\n",
    "    try:\n",
    "        prediction = rfc.predict([\n",
    "            [\n",
    "                le_make.transform([predicted_make])[0],\n",
    "                le_model.transform([predicted_model])[0],\n",
    "                le_format.transform([predicted_format])[0],\n",
    "                le_size_class.transform([predicted_size_class])[0],\n",
    "                le_color1.transform([str(color1)])[0],\n",
    "                le_color2.transform([str(color2)])[0],\n",
    "                le_color3.transform([str(color3)])[0],\n",
    "                le_orientation.transform([predicted_orientation])[0],\n",
    "                le_tag.transform([predicted_tag])[0],\n",
    "            ]\n",
    "        ])\n",
    "    except ValueError as e:\n",
    "        # Handle unseen color values (e.g., predict default favorite)\n",
    "        print(f\"Encountered unseen color values: {e}\")\n",
    "        prediction = [0]  # Example: predict default favorite (adjust based on your logic)\n",
    "    \n",
    "    prediction_array.append({'filename': item['filename'], 'favorite': str(le_favorite.inverse_transform(prediction)).split('[')[1].split(']')[0].replace(\"'\", \"\")})\n",
    "    print(item[\"filename\"])\n",
    "    print(le_favorite.inverse_transform(prediction))\n",
    "    # print(rfc.feature_importances_)\n",
    "\n",
    "\n",
    "filtered_data = [{'filename': item['filename'], 'favorite': item['favorite']} for item in input_data]\n",
    "print(filtered_data)\n",
    "print(prediction_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function get the filename to get recommanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_recommended_files(array1, array2):\n",
    "    # Create dictionaries to store filename-favorite mappings for each array\n",
    "    mapping1 = {item['filename']: item['favorite'] for item in array1}\n",
    "    mapping2 = {item['filename']: item['favorite'] for item in array2}\n",
    "\n",
    "    # Find filenames where array1 is 'NotFavorite' but array2 is 'Favorite'\n",
    "    recommended_files = [filename for filename, favorite1 in mapping1.items() if favorite1 == 'NotFavorite' and mapping2.get(filename) == 'Favorite']\n",
    "\n",
    "    if recommended_files != []:\n",
    "        # Print recommended filenames\n",
    "        print(\"Recommended files:\")\n",
    "        for filename in recommended_files:\n",
    "            print(filename)\n",
    "    else:\n",
    "        print('There are no file to be recommanded for this user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the file to be recommanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_recommended_files(filtered_data, prediction_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
