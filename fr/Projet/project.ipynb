{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "## Dépendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: SPARQLWrapper in /home/warmteapot/.local/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in /home/warmteapot/.local/lib/python3.9/site-packages (from SPARQLWrapper) (7.0.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /home/warmteapot/.local/lib/python3.9/site-packages (from rdflib>=6.1.1->SPARQLWrapper) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/lib/python3/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->SPARQLWrapper) (1.16.0)\n",
      "\u001b[33mDEPRECATION: gpg 1.14.0-unknown has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of gpg or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: exifread in /home/warmteapot/.local/lib/python3.9/site-packages (3.0.0)\n",
      "\u001b[33mDEPRECATION: gpg 1.14.0-unknown has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of gpg or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install SPARQLWrapper\n",
    "! pip install exifread\n",
    "! pip install pandas\n",
    "! pip install PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecte de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ville</th>\n",
       "      <th>pays</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Krasnoïarsk</td>\n",
       "      <td>Russie</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>Brésil</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boston</td>\n",
       "      <td>États-Unis</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Caire</td>\n",
       "      <td>Égypte</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Szczecin</td>\n",
       "      <td>Pologne</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Padoue</td>\n",
       "      <td>Italie</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Argentine</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Lyon</td>\n",
       "      <td>France</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Le Mans</td>\n",
       "      <td>France</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Islamabad</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ville        pays  \\\n",
       "0    Krasnoïarsk      Russie   \n",
       "1      São Paulo      Brésil   \n",
       "2         Boston  États-Unis   \n",
       "3       Le Caire      Égypte   \n",
       "4       Szczecin     Pologne   \n",
       "..           ...         ...   \n",
       "95        Padoue      Italie   \n",
       "96  Buenos Aires   Argentine   \n",
       "97          Lyon      France   \n",
       "98       Le Mans      France   \n",
       "99     Islamabad    Pakistan   \n",
       "\n",
       "                                                image  \n",
       "0   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "1   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "2   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "3   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "4   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "..                                                ...  \n",
       "95  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "96  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "97  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "98  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "99  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# Get cities\n",
    "query = \"\"\"SELECT DISTINCT ?grandeville ?grandevilleLabel ?pays ?paysLabel ?image {\n",
    "  ?grandeville wdt:P31 wd:Q1549591;\n",
    "               wdt:P17 ?pays;\n",
    "               wdt:P18 ?image.\n",
    " SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr\". }\n",
    "}\n",
    "LIMIT 100\"\"\"\n",
    "\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (\n",
    "        sys.version_info[0],\n",
    "        sys.version_info[1],\n",
    "    )\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "\n",
    "array = []\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    array.append(\n",
    "        (\n",
    "            result[\"grandevilleLabel\"][\"value\"],\n",
    "            result[\"paysLabel\"][\"value\"],\n",
    "            result[\"image\"][\"value\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "dataframe = pd.DataFrame(array, columns=[\"ville\", \"pays\", \"image\"])\n",
    "dataframe = dataframe.astype(\n",
    "    dtype={\"ville\": \"<U200\", \"pays\": \"<U200\", \"image\": \"<U200\"}\n",
    ")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Téléchargement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     200\n",
       "1     200\n",
       "2     200\n",
       "3     200\n",
       "4     200\n",
       "     ... \n",
       "95    200\n",
       "96    200\n",
       "97    200\n",
       "98    200\n",
       "99    200\n",
       "Name: image, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def download_image(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    request = requests.get(url, allow_redirects=True, headers=headers, stream=True)\n",
    "    if request.status_code == 200:\n",
    "        # Create 'images' directory if it doesn't exist\n",
    "        if not os.path.exists(\"images\"):\n",
    "            os.makedirs(\"images\")\n",
    "\n",
    "        # Extract the filename from the URL and save the image in 'images' directory\n",
    "        filename = os.path.join(\"images\", os.path.basename(url))\n",
    "        with open(filename, \"wb\") as image:\n",
    "            request.raw.decode_content = True\n",
    "            shutil.copyfileobj(request.raw, image)\n",
    "    return request.status_code\n",
    "\n",
    "def clear_images_directory():\n",
    "    # Clear 'images' directory if it exists\n",
    "    if os.path.exists(\"images\"):\n",
    "        shutil.rmtree(\"images\")\n",
    "\n",
    "# Clear 'images' directory before every execution\n",
    "clear_images_directory()\n",
    "\n",
    "# Assuming 'dataframe' is a DataFrame containing URLs under column 'image'\n",
    "# Apply the download_image function to each URL in the 'image' column\n",
    "dataframe.image.apply(download_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enregistrement des métadonnées\n",
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image, TiffImagePlugin\n",
    "import PIL.ExifTags\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the directory path and initialize the list to store metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"images\"\n",
    "all_metadata = []\n",
    "\n",
    "if not os.path.isdir(directory_path):\n",
    "    print(f\"Error: Directory '{directory_path}' does not exist!\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the function to cast data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast(v):\n",
    "    if isinstance(v, TiffImagePlugin.IFDRational):\n",
    "        if v.denominator == 0:\n",
    "            return None  # Handle division by zero gracefully\n",
    "        return float(v.numerator) / float(v.denominator)\n",
    "    elif isinstance(v, tuple):\n",
    "        return tuple(cast(t) for t in v)\n",
    "    elif isinstance(v, bytes):\n",
    "        return v.decode(errors=\"replace\")\n",
    "    elif isinstance(v, dict):\n",
    "        for kk, vv in v.items():\n",
    "            v[kk] = cast(vv)\n",
    "        return v\n",
    "    else:\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the function to get main colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_main_colors(image_path, num_clusters):\n",
    "    numarray = np.array(image_path.getdata(), dtype=np.uint8)\n",
    "    clusters = KMeans(n_clusters=num_clusters, n_init=2)\n",
    "    clusters.fit(numarray)\n",
    "\n",
    "    main_colors = []\n",
    "    for cluster_center in clusters.cluster_centers_:\n",
    "        main_colors.append(cluster_center.astype(int))\n",
    "\n",
    "    return main_colors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the function to get the images properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_metadata(imgfile, hasExif):\n",
    "    metadata = {}\n",
    "\n",
    "    # Get image format\n",
    "    metadata['format'] = imgfile.format\n",
    "\n",
    "    # Get image size\n",
    "    metadata['size'] = imgfile.size\n",
    "    \n",
    "    # Get 3 main Colors\n",
    "    metadata['main_colors'] = get_main_colors(imgfile, 3)\n",
    "    \n",
    "    if hasExif:\n",
    "        exif = dict(imgfile._getexif().items())\n",
    "        if exif:\n",
    "            # Get image orientation (landscape, portrait, square, etc.)\n",
    "            if 274 in exif:\n",
    "                orientation = exif[274]\n",
    "                if orientation == 1:\n",
    "                    metadata['orientation'] = 'Landscape'\n",
    "                elif orientation == 3:\n",
    "                    metadata['orientation'] = 'Portrait'\n",
    "                else:\n",
    "                    metadata['orientation'] = 'Unknown'\n",
    "            else:\n",
    "                metadata['orientation'] = 'Unknown'\n",
    "    else:\n",
    "        metadata['orientation'] = 'Unknown'\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through files in the directory and extract metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found image: 19-03-03-Maribor-RalfR-DJI%200444.jpg\n",
      "Found image: Szczecin%20aerial%203a.jpg\n",
      "Found image: Omsk%20Collage%202016.png\n",
      "  - No EXIF data found for Omsk%20Collage%202016.png\n",
      "Found image: Zagreb%20%2829255640143%29.jpg\n",
      "Found image: Grenoble%2001.JPG\n",
      "Found image: Stadtbild%20K%C3%B6ln%20%2850MP%29.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from PIL import Image, TiffImagePlugin\n",
    "import PIL.ExifTags\n",
    "\n",
    "directory_path = \"images\"\n",
    "all_metadata = []\n",
    "\n",
    "if not os.path.isdir(directory_path):\n",
    "    print(f\"Error: Directory '{directory_path}' does not exist!\")\n",
    "    sys.exit()\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if os.path.isfile(os.path.join(directory_path, filename)) and filename.lower().endswith((\".jpg\", \".png\")):\n",
    "        print(f\"Found image: {filename}\")\n",
    "\n",
    "        try:\n",
    "            imgfile = Image.open(os.path.join(directory_path, filename))\n",
    "            exif_data = imgfile._getexif()\n",
    "            \n",
    "            metadata_dict = {}\n",
    "            \n",
    "            hasExif = False\n",
    "\n",
    "            if exif_data:\n",
    "                hasExif = True\n",
    "                for k, v in imgfile._getexif().items():\n",
    "                    if k in PIL.ExifTags.TAGS:\n",
    "                        v = cast(v)\n",
    "                        metadata_dict[PIL.ExifTags.TAGS[k]] = v\n",
    "            else:\n",
    "                print(f\"  - No EXIF data found for {filename}\")\n",
    "\n",
    "            # Get additional image metadata (format, size, orientation)\n",
    "            image_metadata = get_image_metadata(imgfile, hasExif)\n",
    "            metadata_dict.update(image_metadata)\n",
    "            \n",
    "            all_metadata.append({filename: metadata_dict})\n",
    "            if not metadata_dict:\n",
    "                print(f\"  - No metadata found for {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error processing {filename}: {e}\")\n",
    "\n",
    "directory_path = \"output\"\n",
    "output_file = \"directory_metadata.json\"\n",
    "\n",
    "if not os.path.exists(directory_path):\n",
    "            os.makedirs(directory_path)\n",
    "\n",
    "output_location = directory_path + \"/\" + output_file\n",
    "with open(output_location, \"w\") as json_file:\n",
    "    json.dump(all_metadata, json_file, indent=4)\n",
    "\n",
    "print(f\"Directory metadata saved to {output_location} (if no errors occurred)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging\n",
    "## Main colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=640x480 at 0x7FF3CFC43880>\n",
      "[array([239, 178,   7]), array([20, 23, 18]), array([63, 79, 61])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_main_colors(image_path, num_clusters):\n",
    "    imgfile = Image.open(image_path)\n",
    "    print(imgfile)\n",
    "    numarray = numpy.array(imgfile.getdata(), numpy.uint8)\n",
    "    clusters = KMeans(n_clusters=num_clusters, n_init=2)\n",
    "    clusters.fit(numarray)\n",
    "\n",
    "    main_colors = []\n",
    "    for cluster_center in clusters.cluster_centers_:\n",
    "        main_colors.append(cluster_center.astype(int))\n",
    "\n",
    "    return main_colors\n",
    "\n",
    "# Example usage:\n",
    "main_colors = get_main_colors(\"../../images/flower.jpg\", 3)\n",
    "print(main_colors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
