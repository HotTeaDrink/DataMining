{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "## Dépendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: SPARQLWrapper in /home/warmteapot/.local/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in /home/warmteapot/.local/lib/python3.9/site-packages (from SPARQLWrapper) (7.0.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /home/warmteapot/.local/lib/python3.9/site-packages (from rdflib>=6.1.1->SPARQLWrapper) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/lib/python3/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->SPARQLWrapper) (1.16.0)\n",
      "\u001b[33mDEPRECATION: gpg 1.14.0-unknown has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of gpg or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: exifread in /home/warmteapot/.local/lib/python3.9/site-packages (3.0.0)\n",
      "\u001b[33mDEPRECATION: gpg 1.14.0-unknown has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of gpg or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install SPARQLWrapper\n",
    "! pip install exifread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecte de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ville</th>\n",
       "      <th>pays</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Krasnoïarsk</td>\n",
       "      <td>Russie</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>Brésil</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boston</td>\n",
       "      <td>États-Unis</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Caire</td>\n",
       "      <td>Égypte</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Szczecin</td>\n",
       "      <td>Pologne</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Padoue</td>\n",
       "      <td>Italie</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Argentine</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Lyon</td>\n",
       "      <td>France</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Le Mans</td>\n",
       "      <td>France</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Islamabad</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ville        pays  \\\n",
       "0    Krasnoïarsk      Russie   \n",
       "1      São Paulo      Brésil   \n",
       "2         Boston  États-Unis   \n",
       "3       Le Caire      Égypte   \n",
       "4       Szczecin     Pologne   \n",
       "..           ...         ...   \n",
       "95        Padoue      Italie   \n",
       "96  Buenos Aires   Argentine   \n",
       "97          Lyon      France   \n",
       "98       Le Mans      France   \n",
       "99     Islamabad    Pakistan   \n",
       "\n",
       "                                                image  \n",
       "0   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "1   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "2   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "3   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "4   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "..                                                ...  \n",
       "95  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "96  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "97  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "98  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "99  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# Get cities\n",
    "query = \"\"\"SELECT DISTINCT ?grandeville ?grandevilleLabel ?pays ?paysLabel ?image {\n",
    "  ?grandeville wdt:P31 wd:Q1549591;\n",
    "               wdt:P17 ?pays;\n",
    "               wdt:P18 ?image.\n",
    " SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr\". }\n",
    "}\n",
    "LIMIT 100\"\"\"\n",
    "\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (\n",
    "        sys.version_info[0],\n",
    "        sys.version_info[1],\n",
    "    )\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "\n",
    "array = []\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    array.append(\n",
    "        (\n",
    "            result[\"grandevilleLabel\"][\"value\"],\n",
    "            result[\"paysLabel\"][\"value\"],\n",
    "            result[\"image\"][\"value\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "dataframe = pd.DataFrame(array, columns=[\"ville\", \"pays\", \"image\"])\n",
    "dataframe = dataframe.astype(\n",
    "    dtype={\"ville\": \"<U200\", \"pays\": \"<U200\", \"image\": \"<U200\"}\n",
    ")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Téléchargement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     200\n",
       "1     200\n",
       "2     200\n",
       "3     200\n",
       "4     200\n",
       "     ... \n",
       "95    200\n",
       "96    200\n",
       "97    200\n",
       "98    200\n",
       "99    200\n",
       "Name: image, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def download_image(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    request = requests.get(url, allow_redirects=True, headers=headers, stream=True)\n",
    "    if request.status_code == 200:\n",
    "        # Create 'images' directory if it doesn't exist\n",
    "        if not os.path.exists(\"images\"):\n",
    "            os.makedirs(\"images\")\n",
    "\n",
    "        # Extract the filename from the URL and save the image in 'images' directory\n",
    "        filename = os.path.join(\"images\", os.path.basename(url))\n",
    "        with open(filename, \"wb\") as image:\n",
    "            request.raw.decode_content = True\n",
    "            shutil.copyfileobj(request.raw, image)\n",
    "    return request.status_code\n",
    "\n",
    "def clear_images_directory():\n",
    "    # Clear 'images' directory if it exists\n",
    "    if os.path.exists(\"images\"):\n",
    "        shutil.rmtree(\"images\")\n",
    "\n",
    "# Clear 'images' directory before every execution\n",
    "clear_images_directory()\n",
    "\n",
    "# Assuming 'dataframe' is a DataFrame containing URLs under column 'image'\n",
    "# Apply the download_image function to each URL in the 'image' column\n",
    "dataframe.image.apply(download_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enregistrement des métadonnées\n",
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image, TiffImagePlugin\n",
    "import PIL.ExifTags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the directory path and initialize the list to store metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"images\"\n",
    "all_metadata = []\n",
    "\n",
    "if not os.path.isdir(directory_path):\n",
    "    print(f\"Error: Directory '{directory_path}' does not exist!\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the function to cast data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast(v):\n",
    "    if isinstance(v, TiffImagePlugin.IFDRational):\n",
    "        if v.denominator == 0:\n",
    "            return None  # Handle division by zero gracefully\n",
    "        return float(v.numerator) / float(v.denominator)\n",
    "    elif isinstance(v, tuple):\n",
    "        return tuple(cast(t) for t in v)\n",
    "    elif isinstance(v, bytes):\n",
    "        return v.decode(errors=\"replace\")\n",
    "    elif isinstance(v, dict):\n",
    "        for kk, vv in v.items():\n",
    "            v[kk] = cast(vv)\n",
    "        return v\n",
    "    else:\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the function to get the images properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_metadata(imgfile):\n",
    "    metadata = {}\n",
    "\n",
    "    # Get image format\n",
    "    metadata['format'] = imgfile.format\n",
    "\n",
    "    # Get image size\n",
    "    metadata['size'] = imgfile.size\n",
    "    \n",
    "    exif = dict(imgfile._getexif().items())\n",
    "    if exif:\n",
    "        # Get image orientation (landscape, portrait, square, etc.)\n",
    "        if 274 in exif:\n",
    "            orientation = exif[274]\n",
    "            if orientation == 1:\n",
    "                metadata['orientation'] = 'Landscape'\n",
    "            elif orientation == 3:\n",
    "                metadata['orientation'] = 'Portrait'\n",
    "            else:\n",
    "                metadata['orientation'] = 'Unknown'\n",
    "        else:\n",
    "            metadata['orientation'] = 'Unknown'\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through files in the directory and extract metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found image: 19-03-03-Maribor-RalfR-DJI%200444.jpg\n",
      "Found image: Szczecin%20aerial%203a.jpg\n",
      "Found image: Omsk%20Collage%202016.png\n",
      "  - No EXIF data found for Omsk%20Collage%202016.png\n",
      "  - Error processing Omsk%20Collage%202016.png: 'NoneType' object has no attribute 'items'\n",
      "Found image: Zagreb%20%2829255640143%29.jpg\n",
      "Found image: Grenoble%2001.JPG\n",
      "Found image: Stadtbild%20K%C3%B6ln%20%2850MP%29.jpg\n",
      "Found image: Venice%20Old%20Town%20Lagoon%20Aerial%20View.jpg\n",
      "  - No EXIF data found for Venice%20Old%20Town%20Lagoon%20Aerial%20View.jpg\n",
      "  - Error processing Venice%20Old%20Town%20Lagoon%20Aerial%20View.jpg: 'NoneType' object has no attribute 'items'\n",
      "Found image: 00%206191%20Maastricht%20-%20Niederlande.jpg\n",
      "Found image: ISS-38%20Nighttime%20image%20of%20Moscow%2C%20Russia.jpg\n",
      "Found image: Vue%20Cath%C3%A9drale%20Jardins%20Pierre%20de%20Ronsard.JPG\n",
      "Found image: Amdavad%20Aerial.jpg\n",
      "  - No EXIF data found for Amdavad%20Aerial.jpg\n",
      "  - Error processing Amdavad%20Aerial.jpg: 'NoneType' object has no attribute 'items'\n",
      "Found image: Trieste%20%2828766391880%29.jpg\n",
      "Found image: 00%200781%20Canal%20in%20Delft%20%28NL%29.jpg\n",
      "Found image: Alexandria%20-%20Egypt.jpg\n",
      "Found image: Ljubljana%20Montage%202.png\n",
      "  - No EXIF data found for Ljubljana%20Montage%202.png\n",
      "  - Error processing Ljubljana%20Montage%202.png: 'NoneType' object has no attribute 'items'\n",
      "Found image: Stone%20Bridge%20Skopje%204.jpg\n",
      "Found image: MaastrichtAltstadt.jpg\n",
      "  - No EXIF data found for MaastrichtAltstadt.jpg\n",
      "  - Error processing MaastrichtAltstadt.jpg: 'NoneType' object has no attribute 'items'\n",
      "Found image: 01.%20Panorama%20de%20Lyon%20pris%20depuis%20le%20toit%20de%20la%20Basilique%20de%20Fourvi%C3%A8re.jpg\n",
      "Found image: Views%20of%20Yekaterinburg%20from%20Vysotsky%20viewpoint%20-%2012.jpg\n",
      "Found image: Landungsbr%C3%BCcken%20Hamburg.jpg\n",
      "Found image: Russian%20church%20%2837591925970%29.jpg\n",
      "Found image: Samara%20-%20Port%20%282008-07-13%29.jpg\n",
      "Found image: Sebastian%20Glapinski%202017%20%28Unsplash%29.jpg\n",
      "Found image: Rynek%20Ko%C5%9Bciuszki%2C%20Bia%C5%82ystok%20%282%29.jpg\n",
      "  - No EXIF data found for Rynek%20Ko%C5%9Bciuszki%2C%20Bia%C5%82ystok%20%282%29.jpg\n",
      "  - Error processing Rynek%20Ko%C5%9Bciuszki%2C%20Bia%C5%82ystok%20%282%29.jpg: 'NoneType' object has no attribute 'items'\n",
      "Found image: Pet%C5%99%C3%ADn%20Tower%20View%20IMG%203020.JPG\n",
      "Found image: Vista%20de%20Tiflis%2C%20Georgia%2C%202016-09-29%2C%20DD%2067-71%20PAN.jpg\n",
      "Found image: Buenos%20Aires%20-%20Puerto%20Madero.jpg\n",
      "Found image: %D3%A8%D0%A4%D3%A8-2015-%28v2%29.jpg\n",
      "  - No EXIF data found for %D3%A8%D0%A4%D3%A8-2015-%28v2%29.jpg\n",
      "Found image: Aerial%20view%20of%20Krasnoyarsk%201.jpg\n",
      "Found image: Milano%20piazza%20Duomo.jpg\n",
      "Found image: Boston%20Financial%20District%20skyline.jpg\n",
      "Found image: San%20Francisco%20from%20the%20Marin%20Headlands%20in%20March%202019.jpg\n",
      "Found image: Turin%20Montage.png\n",
      "  - No EXIF data found for Turin%20Montage.png\n",
      "  - Error processing Turin%20Montage.png: 'NoneType' object has no attribute 'items'\n",
      "Found image: Lausanne%20img%200585.jpg\n",
      "Found image: 00%20sea%20towers%20%28April%202018%29.jpg\n",
      "Found image: La%20Paz-center.jpg\n",
      "Found image: Geneva%20from%20Mount%20Sal%C3%A8ve.jpg\n",
      "Found image: Ghent%20-%20centre.jpg\n",
      "Found image: Sao%20Paulo%20Skyline%20in%20Brazil.jpg\n",
      "Found image: Toronto%20Montage%202020.jpg\n",
      "  - No EXIF data found for Toronto%20Montage%202020.jpg\n",
      "  - Error processing Toronto%20Montage%202020.jpg: 'NoneType' object has no attribute 'items'\n",
      "Found image: KAZ%20Collage%202015.png\n",
      "  - No EXIF data found for KAZ%20Collage%202015.png\n",
      "  - Error processing KAZ%20Collage%202015.png: 'NoneType' object has no attribute 'items'\n",
      "Found image: Chennai%20train%20station.jpg\n",
      "Found image: Altes%20Rathaus%20Bonn.jpg\n",
      "Found image: Novosibirsk%20view.jpg\n",
      "Found image: Katowice%20Rynek.jpg\n",
      "Found image: Oslo%20newer%20montage%202013.png\n",
      "  - No EXIF data found for Oslo%20newer%20montage%202013.png\n",
      "  - Error processing Oslo%20newer%20montage%202013.png: 'NoneType' object has no attribute 'items'\n",
      "Found image: DCmontage2.jpg\n",
      "Found image: Atomium%2C%20Br%C3%BCssel%202.jpg\n",
      "Found image: BangaloreMontage.png\n",
      "  - No EXIF data found for BangaloreMontage.png\n",
      "  - Error processing BangaloreMontage.png: 'NoneType' object has no attribute 'items'\n",
      "Found image: Place%20lazare%20goujon.jpg\n",
      "Found image: Roma%20dall%27aereo.JPG\n",
      "Found image: Lille%20vue%20gd%20place.JPG\n",
      "Found image: 138%20-%20Place%20de%20la%20Bourse%20et%20le%20miroir%20d%27eau%20-%20Bordeaux.jpg\n",
      "Found image: 2017-05-27%20Plac%20Zamkowy%20w%20Warszawie%201.jpg\n",
      "Found image: Large%20Beijing%20Landsat.jpg\n",
      "  - No EXIF data found for Large%20Beijing%20Landsat.jpg\n",
      "  - Error processing Large%20Beijing%20Landsat.jpg: 'NoneType' object has no attribute 'items'\n",
      "Found image: Tokyo%20Japan%20taken%20by%20Hodoyoshi-3%20Satellite.jpg\n",
      "  - No EXIF data found for Tokyo%20Japan%20taken%20by%20Hodoyoshi-3%20Satellite.jpg\n",
      "  - Error processing Tokyo%20Japan%20taken%20by%20Hodoyoshi-3%20Satellite.jpg: 'NoneType' object has no attribute 'items'\n",
      "Found image: Duquesne%20Incline%20%2850076338942%29%20%28cropped%29.jpg\n",
      "Found image: Blick%20AC%20Dom%20von%20St%20Jakob.JPG\n",
      "  - No EXIF data found for Blick%20AC%20Dom%20von%20St%20Jakob.JPG\n",
      "  - Error processing Blick%20AC%20Dom%20von%20St%20Jakob.JPG: 'NoneType' object has no attribute 'items'\n",
      "Found image: Bern%20luftaufnahme.png\n",
      "  - No EXIF data found for Bern%20luftaufnahme.png\n",
      "  - Error processing Bern%20luftaufnahme.png: 'NoneType' object has no attribute 'items'\n",
      "Found image: Raffles%20Place.jpg\n",
      "Found image: NN%2001-09-2021%2006.jpg\n",
      "Found image: DubaiCollage.jpg\n",
      "  - No EXIF data found for DubaiCollage.jpg\n",
      "  - Error processing DubaiCollage.jpg: 'NoneType' object has no attribute 'items'\n",
      "Found image: Stuttgart%20Downtown%20Sights%20Collage.png\n",
      "Found image: Stare%20Miasto%20w%20Poznaniu.jpg\n",
      "Found image: Rhine%20Rhein%20Basel%202006%20871.JPG\n",
      "Found image: Kairo%20BW%201.jpg\n",
      "Found image: Lakhota%20Tower%20in%20evening%20by%20Rangilo.JPG\n",
      "Found image: Urz%C4%85d%20miasta.jpg\n",
      "Found image: Genova%20panorama%20centro%20storico%20da%20villetta%20Di%20Negro.jpg\n",
      "Found image: Heilbronn%20Innenstadt%20u%20Wartberg%2020050918.jpg\n",
      "Found image: Panorama%20modena%2009.jpg\n",
      "Found image: Amsterdam%20airphoto.jpg\n",
      "Found image: Mexico%20City%2C%20Mexico%20%285461525692%29.jpg\n",
      "  - No EXIF data found for Mexico%20City%2C%20Mexico%20%285461525692%29.jpg\n",
      "  - Error processing Mexico%20City%2C%20Mexico%20%285461525692%29.jpg: 'NoneType' object has no attribute 'items'\n",
      "Found image: Padua%20-%20Prato%20della%20Valle.jpg\n",
      "Found image: Rathaus%20HN.JPG\n",
      "Found image: SA%20Montage%20Nima.png\n",
      "  - No EXIF data found for SA%20Montage%20Nima.png\n",
      "  - Error processing SA%20Montage%20Nima.png: 'NoneType' object has no attribute 'items'\n",
      "Found image: Karlsruhe%20asv2022-10%20img07%20Schloss%20Karlsruhe.jpg\n",
      "Found image: Volgograd%20Montage%202016.png\n",
      "  - No EXIF data found for Volgograd%20Montage%202016.png\n",
      "  - Error processing Volgograd%20Montage%202016.png: 'NoneType' object has no attribute 'items'\n",
      "Found image: Montagem%20de%20Lisboa.png\n",
      "  - No EXIF data found for Montagem%20de%20Lisboa.png\n",
      "  - Error processing Montagem%20de%20Lisboa.png: 'NoneType' object has no attribute 'items'\n",
      "Found image: Los%20Angeles%20with%20Mount%20Baldy.jpg\n",
      "Found image: Hoge%20der%20Aa2.jpg\n",
      "Found image: Tomsk%2C%20view%20from%20the%20fire-observation%20tower.jpg\n",
      "  - No EXIF data found for Tomsk%2C%20view%20from%20the%20fire-observation%20tower.jpg\n",
      "  - Error processing Tomsk%2C%20view%20from%20the%20fire-observation%20tower.jpg: 'NoneType' object has no attribute 'items'\n",
      "Found image: Islamabad%20skyline.jpg\n",
      "  - No EXIF data found for Islamabad%20skyline.jpg\n",
      "  - Error processing Islamabad%20skyline.jpg: 'NoneType' object has no attribute 'items'\n",
      "Found image: The%20Upper%20City%20of%20Bergamo.%20View%20from%20Via%20al%20Castello.%20Italy.jpg\n",
      "Found image: Toronto%20Skyline%20March%202023%2014.jpg\n",
      "Found image: Brussels%20view%20from%20Mont%20des%20Arts%2C%20Brussels%2C%20Belgium%20%28cropped%29.jpg\n",
      "Found image: Dortmund%20Panorama.jpg\n",
      "Found image: Zicht%20op%20Zwolle%20Centrum.jpg\n",
      "Found image: ISS043-E-159631%20-%20View%20of%20Earth.jpg\n",
      "Found image: Vue%20sud-ouest%20de%20la%20place%20du%20parlement%20de%20Bretagne%2C%20Rennes%2C%20France.jpg\n",
      "Found image: SalernoCanalone.jpg\n",
      "  - No EXIF data found for SalernoCanalone.jpg\n",
      "  - Error processing SalernoCanalone.jpg: 'NoneType' object has no attribute 'items'\n",
      "Found image: Peter%20%26%20Paul%20fortress%20in%20SPB%2003.jpg\n",
      "Found image: Plovdiv%20mosaic%201.jpg\n",
      "Found image: Big%20Manila.jpg\n",
      "Found image: Loire%20Indre%20Tours1%20tango7174.jpg\n",
      "  - No EXIF data found for Loire%20Indre%20Tours1%20tango7174.jpg\n",
      "  - Error processing Loire%20Indre%20Tours1%20tango7174.jpg: 'NoneType' object has no attribute 'items'\n",
      "Found image: KingsCollegeChapelWest.jpg\n",
      "  - No EXIF data found for KingsCollegeChapelWest.jpg\n",
      "  - Error processing KingsCollegeChapelWest.jpg: 'NoneType' object has no attribute 'items'\n",
      "Found image: Jerusalem%20Dome%20of%20the%20rock%20BW%2014.JPG\n",
      "Found image: Cityscape%20Berlin.jpg\n",
      "Found image: 2010-02-19%203000x2000%20chicago%20skyline.jpg\n",
      "  - No EXIF data found for 2010-02-19%203000x2000%20chicago%20skyline.jpg\n",
      "  - Error processing 2010-02-19%203000x2000%20chicago%20skyline.jpg: 'NoneType' object has no attribute 'items'\n",
      "Found image: Perm%20Russia.jpg\n",
      "Directory metadata saved to directory_metadata.json (if no errors occurred)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from PIL import Image, TiffImagePlugin\n",
    "import PIL.ExifTags\n",
    "\n",
    "directory_path = \"images\"\n",
    "all_metadata = []\n",
    "\n",
    "if not os.path.isdir(directory_path):\n",
    "    print(f\"Error: Directory '{directory_path}' does not exist!\")\n",
    "    sys.exit()\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if os.path.isfile(os.path.join(directory_path, filename)) and filename.lower().endswith((\".jpg\", \".png\")):\n",
    "        print(f\"Found image: {filename}\")\n",
    "\n",
    "        try:\n",
    "            imgfile = Image.open(os.path.join(directory_path, filename))\n",
    "            exif_data = imgfile._getexif()\n",
    "            \n",
    "            metadata_dict = {}\n",
    "\n",
    "            if exif_data:\n",
    "                for k, v in imgfile._getexif().items():\n",
    "                    if k in PIL.ExifTags.TAGS:\n",
    "                        v = cast(v)\n",
    "                        metadata_dict[PIL.ExifTags.TAGS[k]] = v\n",
    "            else:\n",
    "                print(f\"  - No EXIF data found for {filename}\")\n",
    "\n",
    "            # Get additional image metadata (format, size, orientation)\n",
    "            image_metadata = get_image_metadata(imgfile)\n",
    "            metadata_dict.update(image_metadata)\n",
    "            \n",
    "            all_metadata.append({filename: metadata_dict})\n",
    "            if not metadata_dict:\n",
    "                print(f\"  - No metadata found for {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error processing {filename}: {e}\")\n",
    "\n",
    "output_file = \"directory_metadata.json\"\n",
    "with open(output_file, \"w\") as json_file:\n",
    "    json.dump(all_metadata, json_file, indent=4)\n",
    "\n",
    "print(f\"Directory metadata saved to {output_file} (if no errors occurred)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting keras\n",
      "  Downloading keras-3.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting absl-py (from keras)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in /home/warmteapot/.local/lib/python3.9/site-packages (from keras) (1.26.2)\n",
      "Collecting rich (from keras)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting h5py (from keras)\n",
      "  Downloading h5py-3.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes (from keras)\n",
      "  Downloading ml_dtypes-0.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/warmteapot/.local/lib/python3.9/site-packages (from optree->keras) (4.8.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich->keras)\n",
      "  Downloading pygments-2.17.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading keras-3.1.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.9/311.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "\u001b[33mDEPRECATION: gpg 1.14.0-unknown has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of gpg or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: namex, pygments, optree, ml-dtypes, mdurl, h5py, absl-py, markdown-it-py, rich, keras\n",
      "Successfully installed absl-py-2.1.0 h5py-3.10.0 keras-3.1.1 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.7 optree-0.11.0 pygments-2.17.2 rich-13.7.1\n"
     ]
    }
   ],
   "source": [
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained VGG16 model\n",
    "model = VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "# Load and preprocess an image\n",
    "img_path = 'images/Zicht%20op%20Zwolle%20Centrum.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# Use the pre-trained model to make predictions\n",
    "preds = model.predict(x)\n",
    "\n",
    "# Decode the predictions\n",
    "decoded_preds = decode_predictions(preds, top=3)[0]  # Get top 3 predictions\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_preds):\n",
    "    print(f'{i+1}: {label} ({score:.2f})')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
