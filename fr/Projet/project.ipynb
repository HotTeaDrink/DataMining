{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "## Dépendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SPARQLWrapper in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SPARQLWrapper) (7.0.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rdflib>=6.1.1->SPARQLWrapper) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->SPARQLWrapper) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: exifread in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: Loading egg at c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "ERROR: Could not find a version that satisfies the requirement PIL (from versions: none)\n",
      "ERROR: No matching distribution found for PIL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (8.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\guigu\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\guigu\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (8.22.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\guigu\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (5.14.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: decorator in c:\\users\\guigu\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\guigu\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\guigu\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\guigu\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\guigu\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\guigu\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\guigu\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\guigu\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\guigu\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\guigu\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\guigu\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\guigu\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\guigu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "! pip install SPARQLWrapper\n",
    "! pip install exifread\n",
    "! pip install pandas\n",
    "! pip install PIL\n",
    "! pip install ipywidgets\n",
    "! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecte de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ville</th>\n",
       "      <th>pays</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pskov</td>\n",
       "      <td>Russie</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Copenhague</td>\n",
       "      <td>Danemark</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Québec</td>\n",
       "      <td>Canada</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pune</td>\n",
       "      <td>Inde</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Riazan</td>\n",
       "      <td>Russie</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Erfurt</td>\n",
       "      <td>Allemagne</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Djouba</td>\n",
       "      <td>Soudan du Sud</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Edmonton</td>\n",
       "      <td>Canada</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Victoria</td>\n",
       "      <td>Canada</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Francfort-sur-le-Main</td>\n",
       "      <td>Allemagne</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Petrozavodsk</td>\n",
       "      <td>Russie</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Brasilia</td>\n",
       "      <td>Brésil</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Allemagne</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bremerhaven</td>\n",
       "      <td>Allemagne</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Concepción</td>\n",
       "      <td>Chili</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ville           pays  \\\n",
       "0                   Pskov         Russie   \n",
       "1              Copenhague       Danemark   \n",
       "2                  Québec         Canada   \n",
       "3                    Pune           Inde   \n",
       "4                  Riazan         Russie   \n",
       "5                  Erfurt      Allemagne   \n",
       "6                  Djouba  Soudan du Sud   \n",
       "7                Edmonton         Canada   \n",
       "8                Victoria         Canada   \n",
       "9   Francfort-sur-le-Main      Allemagne   \n",
       "10           Petrozavodsk         Russie   \n",
       "11               Brasilia         Brésil   \n",
       "12                Leipzig      Allemagne   \n",
       "13            Bremerhaven      Allemagne   \n",
       "14             Concepción          Chili   \n",
       "\n",
       "                                                image  \n",
       "0   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "1   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "2   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "3   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "4   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "5   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "6   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "7   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "8   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "9   http://commons.wikimedia.org/wiki/Special:File...  \n",
       "10  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "11  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "12  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "13  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "14  http://commons.wikimedia.org/wiki/Special:File...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# Get cities\n",
    "query = \"\"\"SELECT DISTINCT ?grandeville ?grandevilleLabel ?pays ?paysLabel ?image {\n",
    "  ?grandeville wdt:P31 wd:Q1549591;\n",
    "               wdt:P17 ?pays;\n",
    "               wdt:P18 ?image.\n",
    " SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr\". }\n",
    "}\n",
    "LIMIT 15\"\"\"\n",
    "\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (\n",
    "        sys.version_info[0],\n",
    "        sys.version_info[1],\n",
    "    )\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "\n",
    "array = []\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    array.append(\n",
    "        (\n",
    "            result[\"grandevilleLabel\"][\"value\"],\n",
    "            result[\"paysLabel\"][\"value\"],\n",
    "            result[\"image\"][\"value\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "dataframe = pd.DataFrame(array, columns=[\"ville\", \"pays\", \"image\"])\n",
    "dataframe = dataframe.astype(\n",
    "    dtype={\"ville\": \"<U200\", \"pays\": \"<U200\", \"image\": \"<U200\"}\n",
    ")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Téléchargement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     200\n",
       "1     200\n",
       "2     200\n",
       "3     200\n",
       "4     200\n",
       "5     200\n",
       "6     200\n",
       "7     200\n",
       "8     200\n",
       "9     200\n",
       "10    200\n",
       "11    200\n",
       "12    200\n",
       "13    200\n",
       "14    200\n",
       "Name: image, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def download_image(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    request = requests.get(url, allow_redirects=True, headers=headers, stream=True)\n",
    "    if request.status_code == 200:\n",
    "        # Create 'images' directory if it doesn't exist\n",
    "        if not os.path.exists(\"images\"):\n",
    "            os.makedirs(\"images\")\n",
    "\n",
    "        # Extract the filename from the URL and save the image in 'images' directory\n",
    "        filename = os.path.join(\"images\", os.path.basename(url))\n",
    "        with open(filename, \"wb\") as image:\n",
    "            request.raw.decode_content = True\n",
    "            shutil.copyfileobj(request.raw, image)\n",
    "    return request.status_code\n",
    "\n",
    "def clear_images_directory():\n",
    "    # Clear 'images' directory if it exists\n",
    "    if os.path.exists(\"images\"):\n",
    "        shutil.rmtree(\"images\")\n",
    "\n",
    "# Clear 'images' directory before every execution\n",
    "clear_images_directory()\n",
    "\n",
    "# Assuming 'dataframe' is a DataFrame containing URLs under column 'image'\n",
    "# Apply the download_image function to each URL in the 'image' column\n",
    "dataframe.image.apply(download_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enregistrement des métadonnées\n",
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image, TiffImagePlugin\n",
    "import PIL.ExifTags\n",
    "import pandas as pd\n",
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the directory path and initialize the list to store metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"images\"\n",
    "all_metadata = []\n",
    "\n",
    "if not os.path.isdir(directory_path):\n",
    "    print(f\"Error: Directory '{directory_path}' does not exist!\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the function to cast data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast(v):\n",
    "    if isinstance(v, TiffImagePlugin.IFDRational):\n",
    "        if v.denominator == 0:\n",
    "            return None  # Handle division by zero gracefully\n",
    "        return float(v.numerator) / float(v.denominator)\n",
    "    elif isinstance(v, tuple):\n",
    "        return tuple(cast(t) for t in v)\n",
    "    elif isinstance(v, bytes):\n",
    "        return v.decode(errors=\"replace\")\n",
    "    elif isinstance(v, dict):\n",
    "        for kk, vv in v.items():\n",
    "            v[kk] = cast(vv)\n",
    "        return v\n",
    "    else:\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the function to get main colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_main_colors\u001b[39m(image_path, num_clusters):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Open and resize the image\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     imgfile \u001b[38;5;241m=\u001b[39m image_path\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_main_colors(image_path, num_clusters):\n",
    "    # Open and resize the image\n",
    "    imgfile = image_path\n",
    "    imgfile.thumbnail((100, 100))  # Resize the image to a smaller size\n",
    "    numarray = np.array(imgfile)  # Convert image to numpy array\n",
    "\n",
    "    # Flatten the image array\n",
    "    numarray = numarray.reshape((-1, 3))\n",
    "\n",
    "    # Sample a subset of pixels (optional)\n",
    "    np.random.shuffle(numarray)\n",
    "    num_samples = min(10000, len(numarray))  # Adjust the number of samples if needed\n",
    "    numarray = numarray[:num_samples]\n",
    "\n",
    "    # Perform KMeans clustering\n",
    "    clusters = KMeans(n_clusters=num_clusters, n_init=2)\n",
    "    clusters.fit(numarray)\n",
    "\n",
    "    # Get the main colors\n",
    "    main_colors = clusters.cluster_centers_.astype(int)\n",
    "\n",
    "    return main_colors.tolist()  # Convert array to list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to find the closest main color for a given RGB value\n",
    "def find_closest_color(rgb):\n",
    "    main_colors = [\n",
    "        [0, 0, 0],      # Black\n",
    "        [255, 255, 255],  # White\n",
    "        [255, 0, 0],    # Red\n",
    "        [0, 255, 0],    # Green\n",
    "        [0, 0, 255],    # Blue\n",
    "        [255, 255, 0],  # Yellow\n",
    "        [255, 0, 255],  # Magenta\n",
    "        [0, 255, 255],  # Cyan\n",
    "        [128, 128, 128], # Grey\n",
    "        [255, 165, 0],   # Orange\n",
    "        [0, 128, 0],     # Dark Green\n",
    "        [128, 0, 128],   # Purple\n",
    "        [128, 0, 0],     # Maroon\n",
    "        [0, 128, 128],   # Teal\n",
    "        [128, 128, 0],   # Olive\n",
    "        [0, 255, 255],   # Light Blue\n",
    "        [210, 105, 30],  # Chocolate\n",
    "        [139, 69, 19],   # Saddle Brown\n",
    "        [255, 192, 203], # Pink\n",
    "        [0, 0, 128],     # Navy\n",
    "        [220, 20, 60]    # Crimson\n",
    "        # Add more main colors as needed\n",
    "    ]\n",
    "\n",
    "    # Convert list of main colors to numpy array for vectorized calculations\n",
    "    main_colors = np.array(main_colors)\n",
    "\n",
    "    # Convert input RGB list to numpy array\n",
    "    rgb = np.array(rgb)\n",
    "\n",
    "    # Calculate Euclidean distances between input RGB and all main colors\n",
    "    distances = np.linalg.norm(main_colors - rgb, axis=1)\n",
    "\n",
    "    # Find index of the closest main color\n",
    "    closest_index = np.argmin(distances)\n",
    "\n",
    "    return main_colors[closest_index].tolist()  # Convert NumPy array to list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the function to get the images properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_metadata(imgfile, hasExif):\n",
    "    metadata = {}\n",
    "\n",
    "    # Get image format\n",
    "    metadata['format'] = imgfile.format\n",
    "\n",
    "    # Get image size\n",
    "    metadata['size'] = imgfile.size\n",
    "    \n",
    "    # Get 3 main colors\n",
    "    main_colors = get_main_colors(imgfile, 3)\n",
    "    metadata[\"main_colors\"] = main_colors\n",
    "    \n",
    "    # Get closest colors based on the 3 main colors\n",
    "    closest_colors = [find_closest_color(color) for color in main_colors]\n",
    "    \n",
    "    metadata[\"closest_colors\"] = closest_colors\n",
    "    \n",
    "    if hasExif:\n",
    "        exif = dict(imgfile._getexif().items())\n",
    "        if exif:\n",
    "            # Get image orientation (landscape, portrait, square, etc.)\n",
    "            if 274 in exif:\n",
    "                orientation = exif[274]\n",
    "                if orientation == 1:\n",
    "                    metadata['orientation'] = 'Landscape'\n",
    "                elif orientation == 3:\n",
    "                    metadata['orientation'] = 'Portrait'\n",
    "                else:\n",
    "                    metadata['orientation'] = 'Unknown'\n",
    "            else:\n",
    "                metadata['orientation'] = 'Unknown'\n",
    "    else:\n",
    "        metadata['orientation'] = 'Unknown'\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through files in the directory and extract metadata\n",
    "\n",
    "It will also add as tags the format, the size and the 3 main colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from PIL import Image, TiffImagePlugin\n",
    "import PIL.ExifTags\n",
    "\n",
    "directory_path = \"images\"\n",
    "all_metadata = []\n",
    "\n",
    "if not os.path.isdir(directory_path):\n",
    "    print(f\"Error: Directory '{directory_path}' does not exist!\")\n",
    "    sys.exit()\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if os.path.isfile(os.path.join(directory_path, filename)) and filename.lower().endswith((\".jpg\", \".png\")):\n",
    "        print(f\"Found image: {filename}\")\n",
    "\n",
    "        try:\n",
    "            imgfile = Image.open(os.path.join(directory_path, filename))\n",
    "            exif_data = imgfile._getexif()\n",
    "            \n",
    "            metadata_dict = {}\n",
    "            \n",
    "            hasExif = False\n",
    "\n",
    "            if exif_data:\n",
    "                hasExif = True\n",
    "                for k, v in imgfile._getexif().items():\n",
    "                    if k in PIL.ExifTags.TAGS:\n",
    "                        v = cast(v)\n",
    "                        metadata_dict[PIL.ExifTags.TAGS[k]] = v\n",
    "            else:\n",
    "                print(f\"  - No EXIF data found for {filename}\")\n",
    "\n",
    "            # Get additional image metadata (format, size, orientation)\n",
    "            image_metadata = get_image_metadata(imgfile, hasExif)\n",
    "            metadata_dict.update(image_metadata)\n",
    "            \n",
    "            all_metadata.append({filename: metadata_dict})\n",
    "            if not metadata_dict:\n",
    "                print(f\"  - No metadata found for {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error processing {filename}: {e}\")\n",
    "\n",
    "directory_path = \"output\"\n",
    "output_file = \"directory_metadata.json\"\n",
    "\n",
    "if not os.path.exists(directory_path):\n",
    "            os.makedirs(directory_path)\n",
    "\n",
    "output_location = directory_path + \"/\" + output_file\n",
    "with open(output_location, \"w\") as json_file:\n",
    "    json.dump(all_metadata, json_file, indent=4)\n",
    "\n",
    "print(f\"Directory metadata saved to {output_location} (if no errors occurred)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Open the JSON file\n",
    "with open('output/directory_metadata.json', 'r') as file:\n",
    "    # Load the JSON data\n",
    "    json_data = json.load(file)\n",
    "\n",
    "    # Create a list to store all the closest colors\n",
    "    all_closest_colors = []\n",
    "\n",
    "    # Iterate through each object in the list\n",
    "    for obj in json_data:\n",
    "        # Get the dictionary within each object\n",
    "        for filename, details in obj.items():\n",
    "            # Access the \"closest_colors\" key within each dictionary\n",
    "            closest_colors = details.get(\"closest_colors\")\n",
    "            if closest_colors:\n",
    "                # Extend the list of all closest colors with the closest colors of the current image\n",
    "                all_closest_colors.extend(closest_colors)\n",
    "\n",
    "# Count the occurrences of each closest color\n",
    "unique_closest_colors, counts = np.unique(all_closest_colors, axis=0, return_counts=True)\n",
    "\n",
    "# Calculate percentages\n",
    "total_count = sum(counts)\n",
    "percentages = [(count / total_count) * 100 for count in counts]\n",
    "\n",
    "# Create labels with RGB values and percentages\n",
    "labels = [f\"RGB: {color}, {percentage:.2f}%\" for color, percentage in zip(unique_closest_colors, percentages)]\n",
    "sizes = counts\n",
    "colors = [f\"#{r:02x}{g:02x}{b:02x}\" for r, g, b in unique_closest_colors]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sizes, labels=labels, colors=colors, startangle=90)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.title('Pie Chart of Closest Colors')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étiquetage et annotation\n",
    "### Utilisation des utilisateur pour tagger les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import GridspecLayout\n",
    "\n",
    "images = []\n",
    "\n",
    "# Loop through files in the \"./images\" directory\n",
    "for file in listdir(\"./images\"):\n",
    "    # Check if the file is a PNG or JPG image\n",
    "    if file.endswith((\".png\", \".jpg\")):\n",
    "        images.append(\"./images/\" + file)\n",
    "        \n",
    "values = []\n",
    "\n",
    "# Create text boxes\n",
    "text_boxes = [widgets.Text(value='', description='Tag:') for _ in range(len(images))]\n",
    "\n",
    "# Create the GridspecLayout widget\n",
    "layout = GridspecLayout(n_columns=2, n_rows=len(images), width='400px')\n",
    "for i, (img, text_box) in enumerate(zip(images, text_boxes)):\n",
    "    with open(img, \"rb\") as file:\n",
    "        image = file.read()\n",
    "    image_widget = widgets.Image(\n",
    "        value=image,\n",
    "        format='png',\n",
    "        width=100,\n",
    "        height=100,\n",
    "    )\n",
    "    layout[i,0] = image_widget\n",
    "    layout[i, 1] = text_box\n",
    "\n",
    "# Button to get selected images\n",
    "button = widgets.Button(description=\"Select\")\n",
    "\n",
    "# Output widget to display selected values\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to get selected values\n",
    "def get_selected_values(btn):\n",
    "    global values\n",
    "    values = []\n",
    "    selected_values = [(file.split(\"/\")[-1], text_box.value) for file, text_box in zip(images, text_boxes) if text_box.value]\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(\"Selected Values:\")\n",
    "        for file_name, value in selected_values:\n",
    "            print(f\"{file_name}: {value}\")\n",
    "            values.append((file_name, value))\n",
    "    print(values)\n",
    "        \n",
    "\n",
    "# Link button click event to function\n",
    "button.on_click(get_selected_values)\n",
    "\n",
    "# Display the layout and button\n",
    "display(layout, button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the existing JSON file\n",
    "with open('output/directory_metadata.json', 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Iterate through the values and update the JSON data\n",
    "for file_name, value in values:\n",
    "    # Search for the corresponding object in the JSON data\n",
    "    for obj in json_data:\n",
    "        for filename, details in obj.items():\n",
    "            # Check if the file name matches\n",
    "            if filename == file_name:\n",
    "                # Update the value\n",
    "                details['tag'] = value\n",
    "                break  # Exit inner loop if match found\n",
    "        else:\n",
    "            continue  # Continue to next iteration if no match found\n",
    "        break  # Exit outer loop if match found\n",
    "\n",
    "# Save the updated JSON data back to the file\n",
    "with open('output/directory_metadata.json', 'w') as file:\n",
    "    json.dump(json_data, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
